{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-5KBVIjp7nk",
        "outputId": "d5d3bdb3-2110-45b3-82e0-6c5baf4e0e13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. **Imports**"
      ],
      "metadata": {
        "id": "VqZERsaaBImD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math, random\n",
        "from pathlib import Path\n",
        "from typing import Tuple\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "dy3DrQnEBGif"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_split(\n",
        "    in_path,\n",
        "    train_out=\"train.txt\",\n",
        "    valid_out=\"valid.txt\",\n",
        "    valid_ratio=0.05,\n",
        "    seed=42\n",
        "):\n",
        "    random.seed(seed)\n",
        "\n",
        "    text = Path(in_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    random.shuffle(lines)\n",
        "\n",
        "    n_valid = int(len(lines) * valid_ratio)\n",
        "\n",
        "    Path(train_out).write_text(\"\\n\".join(lines[n_valid:]), encoding=\"utf-8\")\n",
        "    Path(valid_out).write_text(\"\\n\".join(lines[:n_valid]), encoding=\"utf-8\")\n",
        "\n",
        "    print(f\"train lines: {len(lines[n_valid:])}\")\n",
        "    print(f\"valid lines: {n_valid}\")"
      ],
      "metadata": {
        "id": "plbKoGKzBUcY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "make_split(\"/content/cleaned-general-text.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpxDXAPcBVxF",
        "outputId": "00a5a904-5e8d-4d88-f1b1-73233c1b65b5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train lines: 175066\n",
            "valid lines: 9213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build SentencePiece Tokenizer with Vocabsize = 8000 (khm_spm.model)"
      ],
      "metadata": {
        "id": "GebMLzHYFDTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 8000\n",
        "\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input=\"train.txt\",\n",
        "    model_prefix=\"kh_spm\",\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    model_type=\"bpe\",\n",
        "    character_coverage=0.9995,\n",
        "    pad_id=0, unk_id=1, bos_id=2, eos_id=3,\n",
        ")\n",
        "\n",
        "sp = spm.SentencePieceProcessor(model_file=\"kh_spm.model\")\n",
        "\n",
        "print(\"Vocab size:\", sp.get_piece_size())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEJG_61LBYl-",
        "outputId": "2d504351-d614-4249-c77a-aaa7f00f2b3c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab size: 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data"
      ],
      "metadata": {
        "id": "f3cH_P_IFaKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LMDataset(Dataset):\n",
        "    def __init__(self, path, sp, block_size=128, step=None):\n",
        "        self.samples = []\n",
        "        step = step or block_size // 2\n",
        "\n",
        "        for line in Path(path).read_text(encoding=\"utf-8\").splitlines():\n",
        "            ids = [sp.bos_id()] + sp.encode(line, out_type=int) + [sp.eos_id()]\n",
        "            for i in range(0, len(ids) - 1, step):\n",
        "                chunk = ids[i:i + block_size + 1]\n",
        "                if len(chunk) >= 2:\n",
        "                    self.samples.append(chunk)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.samples[idx]\n",
        "        return (\n",
        "            torch.tensor(seq[:-1], dtype=torch.long),\n",
        "            torch.tensor(seq[1:], dtype=torch.long)\n",
        "        )"
      ],
      "metadata": {
        "id": "siG0bnFeFBka"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_pad(batch, pad_id):\n",
        "    xs, ys = zip(*batch)\n",
        "    max_len = max(x.size(0) for x in xs)\n",
        "\n",
        "    x_pad = torch.full((len(xs), max_len), pad_id)\n",
        "    y_pad = torch.full((len(xs), max_len), pad_id)\n",
        "\n",
        "    for i, (x, y) in enumerate(zip(xs, ys)):\n",
        "        x_pad[i, :x.size(0)] = x\n",
        "        y_pad[i, :y.size(0)] = y\n",
        "\n",
        "    return x_pad, y_pad\n"
      ],
      "metadata": {
        "id": "nvnSO5-nFeex"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "_6yfCIh_Fhgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMLM(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=256, hid_dim=512, layers=2, pad_id=0):\n",
        "        super().__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=pad_id)\n",
        "        self.lstm = nn.LSTM(\n",
        "            emb_dim, hid_dim, layers,\n",
        "            batch_first=True,\n",
        "            dropout=0.2 if layers > 1 else 0.0\n",
        "        )\n",
        "        self.fc = nn.Linear(hid_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        x = self.emb(x)\n",
        "        x, h = self.lstm(x, h)\n",
        "        return self.fc(x), h\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def step(self, token_id, h=None, device=\"cpu\"):\n",
        "        x = torch.tensor([[token_id]], device=device)\n",
        "        logits, h = self.forward(x, h)\n",
        "        return logits[0, -1], h"
      ],
      "metadata": {
        "id": "OCmJvTFqFfKO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configuration Setup"
      ],
      "metadata": {
        "id": "iEZI614IFlE6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "train_ds = LMDataset(\"train.txt\", sp)\n",
        "valid_ds = LMDataset(\"valid.txt\", sp)\n",
        "\n",
        "train_dl = DataLoader(\n",
        "    train_ds, batch_size=64, shuffle=True,\n",
        "    collate_fn=lambda b: collate_pad(b, sp.pad_id())\n",
        ")\n",
        "valid_dl = DataLoader(\n",
        "    valid_ds, batch_size=64, shuffle=False,\n",
        "    collate_fn=lambda b: collate_pad(b, sp.pad_id())\n",
        ")\n",
        "\n",
        "model = LSTMLM(sp.get_piece_size(), pad_id=sp.pad_id()).to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4)\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
      ],
      "metadata": {
        "id": "azFZu4waFnlY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def generate_text(model, sp, text, max_new_tokens=20):\n",
        "    model.eval()\n",
        "\n",
        "    ids = [sp.bos_id()] + sp.encode(text, out_type=int)\n",
        "    x = torch.tensor(ids, device=device).unsqueeze(0)\n",
        "    h = None\n",
        "\n",
        "    for _ in range(max_new_tokens):\n",
        "        logits, h = model(x[:, -1:], h)\n",
        "        next_id = torch.argmax(logits[0, -1])\n",
        "        x = torch.cat([x, next_id.view(1, 1)], dim=1)\n",
        "        if next_id.item() == sp.eos_id():\n",
        "            break\n",
        "\n",
        "    return sp.decode(x[0].tolist())"
      ],
      "metadata": {
        "id": "vzpNRNujFrPY"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def evaluate():\n",
        "    model.eval()\n",
        "    loss_sum = tok = 0\n",
        "\n",
        "    for x, y in valid_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, _ = model(x)\n",
        "\n",
        "        loss = loss_fn(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            y.view(-1)\n",
        "        )\n",
        "\n",
        "        n = (y != sp.pad_id()).sum().item()\n",
        "        loss_sum += loss.item() * n\n",
        "        tok += n\n",
        "\n",
        "    model.train()\n",
        "    avg_loss = loss_sum / tok\n",
        "    return avg_loss, math.exp(avg_loss)\n"
      ],
      "metadata": {
        "id": "32XE_HrTFqhx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Loop"
      ],
      "metadata": {
        "id": "0Tv2sMaQFv7N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    train_loss_sum = 0\n",
        "    train_tok = 0\n",
        "\n",
        "    for x, y in train_dl:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        logits, _ = model(x)\n",
        "\n",
        "        loss = loss_fn(\n",
        "            logits.view(-1, logits.size(-1)),\n",
        "            y.view(-1)\n",
        "        )\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        n = (y != sp.pad_id()).sum().item()\n",
        "        train_loss_sum += loss.item() * n\n",
        "        train_tok += n\n",
        "\n",
        "    train_loss = train_loss_sum / train_tok\n",
        "    val_loss, val_ppl = evaluate()\n",
        "\n",
        "    print(f\"\\nEpoch {epoch+1}/{EPOCHS}\")\n",
        "    print(f\"Train loss: {train_loss:.4f}\")\n",
        "    print(f\"Val loss  : {val_loss:.4f}\")\n",
        "    print(f\"Val ppl   : {val_ppl:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu9UvxFdFxjK",
        "outputId": "f54a46ca-cb7d-4c68-ae18-5f206b5d12c3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "Train loss: 6.9556\n",
            "Val loss  : 6.1276\n",
            "Val ppl   : 458.35\n",
            "\n",
            "Epoch 2/20\n",
            "Train loss: 5.7056\n",
            "Val loss  : 5.3815\n",
            "Val ppl   : 217.35\n",
            "\n",
            "Epoch 3/20\n",
            "Train loss: 5.1582\n",
            "Val loss  : 5.0294\n",
            "Val ppl   : 152.84\n",
            "\n",
            "Epoch 4/20\n",
            "Train loss: 4.8480\n",
            "Val loss  : 4.8238\n",
            "Val ppl   : 124.44\n",
            "\n",
            "Epoch 5/20\n",
            "Train loss: 4.6315\n",
            "Val loss  : 4.6836\n",
            "Val ppl   : 108.15\n",
            "\n",
            "Epoch 6/20\n",
            "Train loss: 4.4635\n",
            "Val loss  : 4.5749\n",
            "Val ppl   : 97.02\n",
            "\n",
            "Epoch 7/20\n",
            "Train loss: 4.3259\n",
            "Val loss  : 4.4907\n",
            "Val ppl   : 89.18\n",
            "\n",
            "Epoch 8/20\n",
            "Train loss: 4.2084\n",
            "Val loss  : 4.4240\n",
            "Val ppl   : 83.43\n",
            "\n",
            "Epoch 9/20\n",
            "Train loss: 4.1053\n",
            "Val loss  : 4.3639\n",
            "Val ppl   : 78.56\n",
            "\n",
            "Epoch 10/20\n",
            "Train loss: 4.0141\n",
            "Val loss  : 4.3147\n",
            "Val ppl   : 74.79\n",
            "\n",
            "Epoch 11/20\n",
            "Train loss: 3.9317\n",
            "Val loss  : 4.2698\n",
            "Val ppl   : 71.50\n",
            "\n",
            "Epoch 12/20\n",
            "Train loss: 3.8575\n",
            "Val loss  : 4.2333\n",
            "Val ppl   : 68.95\n",
            "\n",
            "Epoch 13/20\n",
            "Train loss: 3.7889\n",
            "Val loss  : 4.1988\n",
            "Val ppl   : 66.61\n",
            "\n",
            "Epoch 14/20\n",
            "Train loss: 3.7273\n",
            "Val loss  : 4.1717\n",
            "Val ppl   : 64.82\n",
            "\n",
            "Epoch 15/20\n",
            "Train loss: 3.6691\n",
            "Val loss  : 4.1457\n",
            "Val ppl   : 63.16\n",
            "\n",
            "Epoch 16/20\n",
            "Train loss: 3.6162\n",
            "Val loss  : 4.1194\n",
            "Val ppl   : 61.52\n",
            "\n",
            "Epoch 17/20\n",
            "Train loss: 3.5665\n",
            "Val loss  : 4.0993\n",
            "Val ppl   : 60.30\n",
            "\n",
            "Epoch 18/20\n",
            "Train loss: 3.5211\n",
            "Val loss  : 4.0802\n",
            "Val ppl   : 59.16\n",
            "\n",
            "Epoch 19/20\n",
            "Train loss: 3.4779\n",
            "Val loss  : 4.0592\n",
            "Val ppl   : 57.93\n",
            "\n",
            "Epoch 20/20\n",
            "Train loss: 3.4378\n",
            "Val loss  : 4.0444\n",
            "Val ppl   : 57.07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Model"
      ],
      "metadata": {
        "id": "7t8I8C1fF0PX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state\": model.state_dict(),\n",
        "    \"vocab_size\": sp.get_piece_size(),\n",
        "    \"pad_id\": sp.pad_id(),\n",
        "    \"emb_dim\": 256,\n",
        "    \"hid_dim\": 512,\n",
        "    \"layers\": 2,\n",
        "}, \"khmer_lstm_lm.pt\")\n",
        "\n",
        "print(\"Model saved: khmer_lstm_lm.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkXKvVVnFzU9",
        "outputId": "dce44778-a3ac-4ef1-f7ac-8c0cff17fb82"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved: khmer_lstm_lm.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing"
      ],
      "metadata": {
        "id": "MAmUMk12F5IW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict_next_word(model, sp, text, top_k=5):\n",
        "    model.eval()\n",
        "\n",
        "    # Encode input\n",
        "    ids = [sp.bos_id()] + sp.encode(text, out_type=int)\n",
        "    h = None\n",
        "\n",
        "    # Feed context except last token\n",
        "    for tid in ids[:-1]:\n",
        "        _, h = model.step(tid, h=h, device=device)\n",
        "\n",
        "    last_token = ids[-1]\n",
        "    logits, _ = model.step(last_token, h=h, device=device)\n",
        "\n",
        "    probs = F.softmax(logits, dim=-1)\n",
        "    top_probs, top_ids = torch.topk(probs, top_k)\n",
        "\n",
        "    results = []\n",
        "    for tid, p in zip(top_ids.tolist(), top_probs.tolist()):\n",
        "        word = sp.decode([int(tid)])   # ✅ convert tensor to int\n",
        "        results.append((word, float(p)))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "OnK4yBpCF4P-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"ខ្ញុំទៅសាលារៀនជាមួយបង\"\n",
        "preds = predict_next_word(model, sp, text)\n",
        "\n",
        "print(\"Input:\", text)\n",
        "print(\"Next word predictions:\")\n",
        "for w, p in preds:\n",
        "    print(f\"  {w}  ({p:.3f})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1yYFbiIF75C",
        "outputId": "50e8bba0-bf78-431a-d7c1-f38f79089897"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: ខ្ញុំទៅសាលារៀនជាមួយបង\n",
            "Next word predictions:\n",
            "  ប្រុស  (0.593)\n",
            "  កែវ  (0.165)\n",
            "  ស្រី  (0.060)\n",
            "  ថ្លៃ  (0.016)\n",
            "  ល  (0.009)\n"
          ]
        }
      ]
    }
  ]
}