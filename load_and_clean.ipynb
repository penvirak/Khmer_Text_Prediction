{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86339507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b46b797",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open(\"general-text.txt\", encoding=\"utf-8\") as f:\n",
    "    for i, line in enumerate(f, 1):\n",
    "        # Split on Khmer punctuation: ៘ ។ ៕ ? and newline\n",
    "        # Note: We keep the punctuation with the text\n",
    "        parts = re.split(r'([៘។៕?])', line)\n",
    "        \n",
    "        # Build sentences while preserving punctuation\n",
    "        current_sentence = \"\"\n",
    "        for part in parts:\n",
    "            if part.strip():  # If part is not empty/whitespace\n",
    "                if part in [\"៘\", \"។\", \"៕\", \"?\", \";\", \",\"]:\n",
    "                    # When we hit punctuation, end the sentence\n",
    "                    current_sentence += part\n",
    "                    data.append({'text': current_sentence.strip()})\n",
    "                    current_sentence = \"\"\n",
    "                else:\n",
    "                    current_sentence += part\n",
    "        \n",
    "        # Don't forget any remaining text\n",
    "        if current_sentence.strip():\n",
    "            data.append({'text': current_sentence.strip()})\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "348fdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean unwanted token\n",
    "unwanted_tokens = [\"៘\",\"។\", \"៕\", \"឴\", \"'\", \"ឝ\", \":\", \"៙\", \";\", \"៚\", '\"', \"៛\", \"៖\", \" \", \"ឞ\", \"\\t\"]\n",
    "\n",
    "def clean_khmer_text(text):\n",
    "    \"\"\"\n",
    "    Keep only Khmer characters and basic punctuation\n",
    "    Remove specific unwanted tokens\n",
    "    \"\"\"\n",
    "    # Khmer Unicode ranges and allowed characters\n",
    "    khmer_range = ('\\u1780-\\u17FF')\n",
    "    \n",
    "    # Allow basic punctuation and numbers (EXCEPT unwanted ones)\n",
    "    allowed_extras = '០១២៣៤៥៦៧៨៩\"\\' :;\\n\\t'\n",
    "    \n",
    "    import re\n",
    "    # First: Keep only Khmer + allowed extras\n",
    "    pattern = f'[{khmer_range}{re.escape(allowed_extras)}]'\n",
    "    cleaned = re.findall(pattern, text)\n",
    "    result = ''.join(cleaned)\n",
    "    \n",
    "    # Second: Remove your specific unwanted tokens\n",
    "    for token in unwanted_tokens:\n",
    "        result = result.replace(token, '')\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Apply to your dataframe\n",
    "df['text'] = df['text'].apply(clean_khmer_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b91e616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows : 556974\n",
      "Number of string >= 70 : 215981 \n",
      "Min : 0\n",
      "Max : 3375\n"
     ]
    }
   ],
   "source": [
    "count_empty_string = 0\n",
    "string_length = []\n",
    "for str in df[\"text\"]:\n",
    "    string_length.append(len(str))\n",
    "    if len(str) >= 70:\n",
    "        count_empty_string+=1\n",
    "\n",
    "print(f\"Total Rows : {len(df['text'])}\")\n",
    "print(f\"Number of string >= 70 : {count_empty_string} \")\n",
    "print(f\"Min : {min(string_length)}\")\n",
    "print(f\"Max : {max(string_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8baae456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Rows : 556974\n",
      "Number of string < 1000 : 556486 \n",
      "Min : 0\n",
      "Max : 3375\n"
     ]
    }
   ],
   "source": [
    "count_empty_string = 0\n",
    "string_length = []\n",
    "for str in df[\"text\"]:\n",
    "    string_length.append(len(str))\n",
    "    if len(str) < 700:\n",
    "        count_empty_string+=1\n",
    "\n",
    "print(f\"Total Rows : {len(df['text'])}\")\n",
    "print(f\"Number of string < 1000 : {count_empty_string} \")\n",
    "print(f\"Min : {min(string_length)}\")\n",
    "print(f\"Max : {max(string_length)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57449282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered 204627 rows with length between 75 and 700\n"
     ]
    }
   ],
   "source": [
    "# Alternative using .loc\n",
    "df_filtered = df.loc[(df['text'].str.len() >= 75) & (df['text'].str.len() <= 700)].copy()\n",
    "\n",
    "print(f\"Filtered {len(df_filtered)} rows with length between 75 and 700\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d769d11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned text to ../data/cleaned-general-text.txt\n"
     ]
    }
   ],
   "source": [
    "out_path = \"../data/cleaned-general-text.txt\"\n",
    "\n",
    "with open(out_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for line in df[\"text\"]:\n",
    "        if pd.notna(line):\n",
    "            text = line.strip()\n",
    "            if text:\n",
    "                f.write(text + \"\\n\")\n",
    "\n",
    "print(f\"Saved cleaned text to {out_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
